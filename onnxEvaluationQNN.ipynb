{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data.npz\n",
    "\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "model_file = 'model.qnn'\n",
    "\n",
    "options = onnxruntime.SessionOptions()\n",
    "options.add_session_config_entry(\"session.disable_cpu_ep_fallback\", \"1\")\n",
    "ort_session = onnxruntime.InferenceSession(model_file + '.onnx',\n",
    "                                       sess_options=options,\n",
    "                                       providers=[\"QNNExecutionProvider\"],\n",
    "                                       provider_options=[{\"backend_path\": \"QnnHtp.dll\"}])\n",
    "\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name\n",
    "print(input_name, output_name)\n",
    "print(\"Available providers:\", ort_session.get_providers())\n",
    "print(\"Current provider:\", ort_session.get_provider_options())\n",
    "\n",
    "# 加载npz文件中的数据\n",
    "data = np.load(r'data\\imagenet\\validation\\_data.npz')\n",
    "images = data['images']\n",
    "labels = data['labels']\n",
    "\n",
    "# 用于存储每个图像的预测标签\n",
    "predicted_labels = []\n",
    "\n",
    "# 逐个图像进行推理\n",
    "for image in images:\n",
    "    # 调整图像形状以匹配模型输入要求（通常添加一个批次维度）\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # 对单个图像进行推理\n",
    "    outputs = ort_session.run([output_name], {input_name: image})\n",
    "    # 获取该图像的预测标签\n",
    "    predicted_label = np.argmax(outputs[0], axis=1)[0]\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# 获取预测标签\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = (predicted_labels == labels).mean()\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use src Image + _label.txt\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "model_file = 'model.fixed'\n",
    "\n",
    "options = onnxruntime.SessionOptions()\n",
    "options.add_session_config_entry(\"session.disable_cpu_ep_fallback\", \"1\")\n",
    "ort_session = onnxruntime.InferenceSession(model_file + '.onnx',\n",
    "                                       sess_options=options,\n",
    "                                       providers=[\"QNNExecutionProvider\"],\n",
    "                                       provider_options=[{\"backend_path\": \"QnnHtp.dll\"}])\n",
    "\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name\n",
    "print(input_name, output_name)\n",
    "print(\"Available providers:\", ort_session.get_providers())\n",
    "print(\"Current provider:\", ort_session.get_provider_options())\n",
    "\n",
    "# 定义图像预处理步骤\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert('RGB')\n",
    "    image = preprocess(image)\n",
    "    image = image.unsqueeze(0)  # 添加批次维度\n",
    "    return image\n",
    "\n",
    "# 加载 labels.txt 文件并解析标签\n",
    "def load_labels(labels_file):\n",
    "    labels = {}\n",
    "    with open(labels_file, 'r') as f:\n",
    "        for line in f:\n",
    "            image_name, label = line.strip().split(',')\n",
    "            labels[image_name] = int(label)\n",
    "    return labels\n",
    "\n",
    "# 计算准确率\n",
    "def calculate_accuracy(validation_folder, label_file):\n",
    "    labels = load_labels(label_file)\n",
    "    correct_predictions = 0\n",
    "    total_images = 0\n",
    "\n",
    "    for image_name in os.listdir(validation_folder):\n",
    "        if image_name.endswith('.jpg'):\n",
    "            image_path = os.path.join(validation_folder, image_name)\n",
    "            image_data = preprocess_image(image_path)\n",
    "            ort_inputs = {ort_session.get_inputs()[0].name: image_data.numpy()}\n",
    "            ort_outs = ort_session.run(None, ort_inputs)\n",
    "            predicted_label = np.argmax(ort_outs[0])\n",
    "\n",
    "            if predicted_label == labels[image_name]:\n",
    "                correct_predictions += 1\n",
    "            total_images += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_images\n",
    "    return accuracy\n",
    "\n",
    "validation_dir = r'data\\imagenet\\validation'\n",
    "calculate_accuracy(validation_dir, os.path.join(validation_dir, '_labels.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
